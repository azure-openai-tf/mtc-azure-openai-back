"""
@created_by ayaan
@created_at 2023.05.08
"""
import os
import urllib
import requests
from collections import OrderedDict
from IPython.display import display, HTML

# LangCahin & OpenAI íŒ¨í‚¤ì§€
import langchain
import openai
from langchain.chat_models import AzureChatOpenAI
from langchain.vectorstores import FAISS
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.embeddings import OpenAIEmbeddings

from dotenv import load_dotenv

load_dotenv()


class AzureOpenAIUtils:
    """Azure OpenAI Utilities"""

    azure_search_key = os.environ.get("SEARCH_KEY")
    azure_search_endpoint = os.environ.get("SEARCH_ENDPOINT")
    azure_search_api_version = "2021-04-30-preview"
    azure_openai_key = os.environ.get("OPEN_AI_KEY")
    azure_openai_endpoint = os.environ.get("OPEN_AI_ENDPOINT")
    azure_openai_api_version = "2023-03-15-preview"

    def __init__(self):
        self.headers = {"Content-Type": "application/json", "api-key": self.azure_search_key}
        self.params = {"api-version": self.azure_search_api_version}  # ìµœì‹  Preview ë²„ì „ 2021-04-30-preview

        # Azure OpenAI ì—°ê²° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        openai.api_type = "azure"  # ì¤‘ìš”!
        openai.api_version = self.azure_openai_api_version  # ìµœì‹  preview ë²„ì „ 2023-03-15-preview
        openai.api_base = self.azure_openai_endpoint
        openai.api_key = self.azure_openai_key

    async def execute_openai(self):
        """Excute OpenAI

        Returns:
            : _description_
        """

        # ì§ˆë¬¸ ì„¤ì •
        # QUESTION = 'How much is GPT-4 Uniform Bar Exam score? give me exact score number'

        # ì§ˆë¬¸ ì„¤ì •
        # QUESTION = ' Azure ê´€ë¦¬ì ìê²©ì¦ì¤‘ì— ì–´ë–¤ ìê²©ì¦ì´ ìˆëŠ”ì§€ ì•„ì£¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜' --> ì´ ë©”ì‹œì§€ë¥¼ ë„£ìœ¼ë©´ ì—ëŸ¬ê°€ ë‚œë‹¤..
        question = " Azure ê´€ë¦¬ìê°€ ë˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ëŠ”ì§€ ìê²©ì¦ë„ ì„¤ëª…í•´ì£¼ê³  ì•Œë ¤ì¤˜"

        # Azure Cognitive Search REST API í˜¸ì¶œ(get)

        index_name = "ai-azureblob-index"

        url = self.azure_search_endpoint + "/indexes/" + index_name + "/docs"
        url += "?api-version={}".format(self.azure_openai_api_version)
        url += "&search={}".format(QUESTION)  # ì§ˆë¬¸
        url += "&select=*"
        # url += '&$top=5'  # ë¬¸ì„œ ê°œìˆ˜ ì œí•œ
        url += "&queryLanguage=en-US"
        url += "&queryType=semantic"  # ì˜ë¯¸ ì²´ê³„ ê²€ìƒ‰
        url += "&semanticConfiguration=semantic-config"
        url += "&$count=true"
        url += "&speller=lexicon"  # ì¿¼ë¦¬ ë§ì¶¤ë²• ê²€ì‚¬
        url += "&answers=extractive|count-3"
        url += "&captions=extractive|highlight-false"

        params = {
            "api-version": self.azure_openai_api_version,
            "search": question,
            "queryLanguage": "en-US",
            "queryType": "semantic",
            "semanticConfiguration": "semantic-config",
            "select": "*",
            "$count": "true",
            "speller": "lexicon",
            "answers": "extractive|count-3",
            "captions": "extractive|highlight-false",
        }

        resp = requests.get(url, headers=headers)
        search_results = resp.json()  # ê²°ê³¼ê°’

        print("API í˜¸ì¶œ ê²°ê³¼ :", resp.status_code)

        # print(search_results)
        # semantic-config ì„¤ì • ê¼­ í•„ìš”
        print("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {}, : ìƒìœ„ ë¬¸ì„œ ìˆ˜: {}".format(search_results["@odata.count"], len(search_results["value"])))

        display(HTML("<h4>ìƒìœ„ ì—°ê´€ ë¬¸ì„œ</h4>"))

        file_content = OrderedDict()
        for result in search_results["value"]:
            # print('result : ' , result)
            # print(result['@search.rerankerScore'])
            # print('file_content : ', file_content)
            print("path : ", result["metadata_storage_path"])
            if result["@search.rerankerScore"] > 0.04:  # Semantic Search ìµœëŒ€ ì ìˆ˜ 4ì , ìƒìœ„ 40%
                # print('##########################################################################################################')
                display(HTML("<h1>" + str(result["metadata_storage_name"]) + ", score: " + str(result["@search.rerankerScore"]) + "</h1>"))
                display(HTML(result["@search.captions"][0]["text"]))
                file_content[result["metadata_storage_path"]] = {
                    "chunks": result["pages"][:1],
                    "caption": result["@search.captions"][0]["text"],
                    "score": result["@search.rerankerScore"],
                    "file_name": result["metadata_storage_name"],
                }
                # print('file_content : ', file_content)

        # AzureOpenAI Service ì—°ê²°
        # ë¬¸ì„œ ë¶„í• 
        docs = []
        for key, value in file_content.items():
            # print('key : ' , key , '\t value : ' , value)
            # print(value['chunks'])
            for page in value["chunks"]:
                docs.append(Document(page_content=page, metadata={"source": value["file_name"]}))
        print("Number of chunks:", len(docs))
        # print('#####################################################')
        # print('docs : ' , docs)

        # Embedding ëª¨ë¸ ìƒì„±
        # ì•„ë˜ì†ŒìŠ¤ì—ì„œ chunk_size=1 ì´ ì•„ë‹Œ ë‹¤ë¥¸ ê°’ì„ ë„£ìœ¼ë©´ ë‹¤ìŒ ì†ŒìŠ¤ì—ì„œ ì—ëŸ¬ê°€ ë‚œë‹¤.
        embeddings = OpenAIEmbeddings(model="text-embedding-ada-002", chunk_size=1, openai_api_key=AZURE_OPENAI_KEY)  # Azure OpenAI embedding ì‚¬ìš©ì‹œ ì£¼ì˜
        # Vector Store ìƒì„±
        # vevtor_store = FAISS.from_documents(docs, embeddings)
        # Chroma vector dbì— ë„£ìŒ
        persist_directory = "db"
        vevtor_store = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=persist_directory)
        # vevtor_store = Chroma.from_documents(docs, embeddings)

        # LangChainğŸ¦œ & Azure GPTğŸ¤– ì—°ê²°
        # llm = AzureChatOpenAI(deployment_name='gpt-35-turbo',  openai_api_key=AZURE_OPENAI_KEY, openai_api_base=AZURE_OPENAI_ENDPOINT, openai_api_version=AZURE_OPENAI_API_VERSION,
        llm = AzureChatOpenAI(
            deployment_name="gpt-35-turbo",
            openai_api_key=AZURE_OPENAI_KEY,
            openai_api_base=AZURE_OPENAI_ENDPOINT,
            openai_api_version=AZURE_OPENAI_API_VERSION,
            temperature=0.0,
            max_tokens=1000,
        )

        # https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html
        qa = RetrievalQAWithSourcesChain.from_chain_type(
            llm=llm,
            # chain_type='stuff',
            chain_type="map_reduce",
            retriever=vevtor_store.as_retriever(),
            return_source_documents=True,
        )

        print(qa)

        result = qa({"question": QUESTION})
        # ë‹µë³€ ê¸€ììˆ˜ ì¹´ìš´íŠ¸
        # char_counts=0
        # ls_str = list(map(str,result))
        # for ls_str1 in ls_str:
        #   char_counts = char_counts + len(ls_str1)

        # print(char_counts)

        print("ì§ˆë¬¸ :", QUESTION)
        print("ë‹µë³€ :", result["answer"])
        print("ğŸ“„ ì°¸ê³  ìë£Œ :", result["sources"].replace(",", "\n"))
